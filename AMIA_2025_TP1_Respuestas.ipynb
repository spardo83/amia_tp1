{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YoTVCUtTQL6c"
   },
   "source": [
    "# TP 1: LDA/QDA y optimización matemática de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.qda import QDA, TensorizedQDA, FastQDA, EfficientQDA\n",
    "from base.cholesky import QDA_Chol1, QDA_Chol2, QDA_Chol3, TensorizedChol, EfficientChol\n",
    "from utils.bench import Benchmark\n",
    "from utils.datasets import (get_iris_dataset, get_letters_dataset, \n",
    "                            get_penguins_dataset, get_wine_dataset,\n",
    "                            label_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consigna QDA\n",
    "\n",
    "**Notación**: en general notamos\n",
    "\n",
    "* $k$ la cantidad de clases\n",
    "* $n$ la cantidad de observaciones\n",
    "* $p$ la cantidad de features/variables/predictores\n",
    "\n",
    "**Sugerencia:** combinaciones adecuadas de `transpose`, `stack`, `reshape` y, ocasionalmente, `flatten` y `diagonal` suele ser más que suficiente. Se recomienda *fuertemente* explorar la dimensionalidad de cada elemento antes de implementar las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorización\n",
    "\n",
    "En esta sección nos vamos a ocupar de hacer que el modelo sea más rápido para generar predicciones, observando que incurre en un doble `for` dado que predice en forma individual un escalar para cada observación, para cada clase. Paralelizar ambos vía tensorización suena como una gran vía de mejora de tiempos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Diferencias entre `QDA`y `TensorizedQDA`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Sobre qué paraleliza `TensorizedQDA`? ¿Sobre las $k$ clases, las $n$ observaciones a predecir, o ambas?\n",
    "\n",
    "   Paraleliza sobre las $k$ clases.\n",
    "\n",
    "   El método _fit_params(X,y) de la clase derivada `TensorizedQDA` obtiene de la clase base `QDA` las inversas de las matrices de covarianzas y vectores de medias de cada clase como dos listas, cada elemento correspondiente a una clase.\n",
    "   - Tipo `means` e `inv_covs`: <class 'list'>.\n",
    "   - Cantidad de elementos de las listas: $k$ (uno por clase).\n",
    "   - Formato elementos lista `means`: (p, 1).\n",
    "   - Formato elementos lista `inv_covs`: (p, p).\n",
    "\n",
    "   Luego, utiliza el método `stack` de numpy para \"apilar\" los elementos de las listas en un tensor de una dimensión adicional a la de los elementos. El primer eje del tensor corresponde al índice de la clase aplilada (`batch`).\n",
    "   - Tipo `tensor_means` y `tensor_inv_covs`: <class 'numpy.ndarray'>.\n",
    "   - Formato `tensor_means`: (k, p, 1).\n",
    "   - Formato `tensor_inv_covs`: (k, p, p).\n",
    "\n",
    "   Este arreglo hace que la multiplicación matricial (@) interprete las dos últimas dimensiones del tensor como matrices a multiplicar y las restantes como índices de lote (batch), realizando las operaciones en paralelo sobre las clases. De modo análogo, np.linalg.det calcula los determinantes en paralelo reconociendo los lotes de matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Analizar los shapes de `tensor_inv_covs` y `tensor_means` y explicar paso a paso cómo es que `TensorizedQDA` llega a predecir lo mismo que `QDA`.\n",
    "\n",
    "   Los shapes de `tensor_inv_covs` y `tensor_means` y como son obtenidos se analizaron en el punto anterior.\n",
    "\n",
    "   `TensorizedQDA` optimiza paralelizando el cálculo de la log-condicional para cada clase dada una observación. Para eso sobreescribe el método `_predict_one` de la clase base, eliminando el lazo `for` donde se realizaba el cálculo de esta probabilidad para cada clase y definiendo el método `_predict_log_conditionals` donde este cálculo se realiza en paralelo a partir de los tensores `tensor_inv_covs` y `tensor_means` mencionados.\n",
    "\n",
    "   Paso a paso:\n",
    "\n",
    "   1) Entrenamiento\n",
    "\n",
    "   Se obtienen las listas de medias e inversas de matrices de covarianzas de cada clase de idéntico modo que en `QDA`. Se sobreescribe el método `_fit_params` para llamar primero al de la clase base QDA y luego generar las versiones tensorizadas.\n",
    "\n",
    "   ```python\n",
    "   def _fit_params(self, X, y):\n",
    "        super()._fit_params(X,y)\n",
    "        self.tensor_inv_cov = np.stack(self.inv_covs)\n",
    "        self.tensor_means = np.stack(self.means)\n",
    "   ```\n",
    "\n",
    "   Basicamente, el entrenamiento en sí es idéntico en ambos casos.\n",
    "\n",
    "   2) Predicción:\n",
    "\n",
    "   Se sobreescribe el método `_predict_one` de la clase `BaseBayesianClassifier`eliminando el lazo `for` y devolviendo el indice de clase como el mayor de la suma del array de probabilidades a priori y del array de log-condicionales de cada clase obtenidas de forma vectorizada en el nuevo método `_predict_log_conditionals`.\n",
    "\n",
    "   ```python\n",
    "   def _predict_one(self, x):\n",
    "        return np.argmax(self.log_a_priori + self._predict_log_conditionals(x)) \n",
    "   ```\n",
    "   En el método `_predict_log_conditionals` obtiene 'unbiased_x' e 'inner_prod' para todas las clases (broadcast, matmul batcheado) de forma simultanea, y luego calcula todas las log-prob de todas las clases juntas\n",
    "\n",
    "   ```python\n",
    "   def _predict_log_conditionals(self,x):\n",
    "        unbiased_x = x - self.tensor_means\n",
    "        inner_prod = unbiased_x.transpose(0,2,1) @ self.tensor_inv_cov @ unbiased_x\n",
    "        return 0.5*np.log(LA.det(self.tensor_inv_cov)) - 0.5 * inner_prod.flatten()\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Optimización\n",
    "\n",
    "Debido a la forma cuadrática de QDA, no se puede predecir para $n$ observaciones en una sola pasada (utilizar $X \\in \\mathbb{R}^{p \\times n}$ en vez de $x \\in \\mathbb{R}^p$) sin pasar por una matriz de $n \\times n$ en donde se computan todas las interacciones entre observaciones. Se puede acceder al resultado recuperando sólo la diagonal de dicha matriz, pero resulta ineficiente en tiempo y (especialmente) en memoria. Aún así, es *posible* que el modelo funcione más rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementar el modelo `FasterQDA` (se recomienda heredarlo de `TensorizedQDA`) de manera de eliminar el ciclo for en el método predict.\n",
    "\n",
    "   Implementado en 'base/qda.py'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Mostrar dónde aparece la mencionada matriz de $n \\times n$, donde $n$ es la cantidad de observaciones a predecir.\n",
    "   \n",
    "   En el método que calcula la log-condicional para todas las clases y observaciones.\n",
    "\n",
    "   ```python\n",
    "   def _predict_log_conditionals_batch(self, x):\n",
    "        \"\"\"\n",
    "        Calcula en paralelo (sobre k y n) los log-condicionales devolviendo una matriz (k, n).\n",
    "\n",
    "        Notas:\n",
    "        1) Se desplazan todas las observaciones por la media de cada clase:\n",
    "               U[k] = X - μ_k     → U.shape = (k, p, n)\n",
    "        2) Se construye la matriz n×n por clase:\n",
    "               M[k] = U[k]^T Σ_k^{-1} U[k]   → M.shape = (k, n, n)\n",
    "        3) Se extrae la diagonal por clase (término cuadrático por observación):\n",
    "               quad[k, i] = (x_i-μ_k)^T Σ_k^{-1} (x_i-μ_k)  → quad.shape = (k, n)\n",
    "        4) Se suma el término 0.5·log|Σ_k^{-1}| (expandido a (k,1)) y se resta\n",
    "           0.5·quad para obtener (k, n).\n",
    "        \"\"\"\n",
    "        # U[k] = X - μ_k  → (k, p, n)  (broadcasting en eje de clases)\n",
    "        U = x - self.tensor_means\n",
    "\n",
    "        # M = U^T Σ_k^{-1} U → (k, n, n)  (matmul batcheado sobre k)\n",
    "        M = U.transpose(0, 2, 1) @ self.tensor_inv_cov @ U\n",
    "\n",
    "        # Diagonal por clase: q_{k,i} = (x_i-μ_k)^T Σ_k^{-1} (x_i-μ_k) → (k, n)\n",
    "        quad = np.diagonal(M, axis1=1, axis2=2)\n",
    "\n",
    "        # 0.5·log|Σ_k^{-1}| → (k,)  ⇒ (k,1) para broadcast sobre n\n",
    "        logdet = 0.5 * np.log(LA.det(self.tensor_inv_cov)).reshape(-1, 1)\n",
    "\n",
    "        # Log-condicional\n",
    "        return logdet - 0.5 * quad  # (k, n)\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Demostrar que\n",
    "   $$\n",
    "   diag(A \\cdot B) = \\sum_{cols} A \\odot B^T = np.sum(A \\odot B^T, axis=1)\n",
    "   $$ es decir, que se puede \"esquivar\" la matriz de $n \\times n$ usando matrices de $n \\times p$. También se puede usar, de forma equivalente,\n",
    "   $$\n",
    "   np.sum(A^T \\odot B, axis=0).T\n",
    "   $$\n",
    "   queda a preferencia del alumno cuál usar.\n",
    "\n",
    "   El producto matricial es  \n",
    "   $$\n",
    "   C = AB, \\quad C \\in \\mathbb{R}^{n \\times n}.\n",
    "   $$  \n",
    "\n",
    "   La diagonal de $C$ es el vector  \n",
    "   $$\n",
    "   diag(C) =\n",
    "   \\begin{bmatrix}\n",
    "   \\sum_{k=1}^p A_{1k} B_{k1} \\\\\n",
    "   \\sum_{k=1}^p A_{2k} B_{k2} \\\\\n",
    "   \\vdots \\\\\n",
    "   \\sum_{k=1}^p A_{nk} B_{kn}\n",
    "   \\end{bmatrix}.\n",
    "   $$  \n",
    "\n",
    "   Para cada $i$:  \n",
    "   $$\n",
    "   C_{ii} = \\sum_{k=1}^p A_{ik} \\cdot (B^T)_{ik}.\n",
    "   $$  \n",
    "\n",
    "   Esto corresponde al producto escalar entre la fila $i$ de $A$ y la fila $i$ de $B^T$.  \n",
    "   Por lo tanto,  \n",
    "   $$\n",
    "   diag(AB) = \\sum_{k=1}^p A_{:,k} \\odot B^T_{:,k}.\n",
    "   $$  \n",
    "\n",
    "   En notación de NumPy:  \n",
    "   $$\n",
    "   diag(AB) = np.sum(A \\odot B^T, axis=1).\n",
    "   $$  \n",
    "\n",
    "   Aquí $A \\odot B^T$ es de dimensión $n \\times p$, y al sumar sobre las columnas se obtiene un vector de longitud $n$.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Utilizar la propiedad antes demostrada para reimplementar la predicción del modelo `FasterQDA` de forma eficiente en un nuevo modelo `EfficientQDA`.\n",
    "\n",
    "   Implementado en base/qda.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Comparar la performance de las 4 variantes de QDA implementadas hasta ahora (no Cholesky) ¿Qué se observa? A modo de opinión ¿Se condice con lo esperado?\n",
    "\n",
    "   Se observan tiempo y uso de memoria similar en entrenamiento. En prueba las implementaciones tensorizadas bajan el tiempo a costo de aumentar el consumo de memoria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benching params:\n",
      "Total runs: 1220\n",
      "Warmup runs: 20\n",
      "Peak Memory usage runs: 200\n",
      "Running time runs: 1000\n",
      "Train size rows (approx): 240\n",
      "Test size rows (approx): 102\n",
      "Test size fraction: 0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179d6704bcc6496ebdc2eea4a86acc99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA (MEM):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e7ba73ae52428d8d7c47199a9ff266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA (TIME):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a3f272ffe04decb07f297b4279e9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TensorizedQDA (MEM):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02eae7cc7f1a444f8d2b2064b05c94fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TensorizedQDA (TIME):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28ba734f54f4d598bf0ae5933c8124a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FastQDA (MEM):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c37e89a718458d8796051b9cef6e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FastQDA (TIME):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9bec628ded466e990c3ad4693d9ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EfficientQDA (MEM):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b62301674e94e89929b95967bd3cb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EfficientQDA (TIME):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_median_ms</th>\n",
       "      <th>test_median_ms</th>\n",
       "      <th>train_mem_median_mb</th>\n",
       "      <th>test_mem_median_mb</th>\n",
       "      <th>mean_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.49545</td>\n",
       "      <td>7.29685</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.987049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorizedQDA</th>\n",
       "      <td>0.42880</td>\n",
       "      <td>2.44300</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.986369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FastQDA</th>\n",
       "      <td>0.40715</td>\n",
       "      <td>0.09810</td>\n",
       "      <td>0.011269</td>\n",
       "      <td>0.264603</td>\n",
       "      <td>0.987165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EfficientQDA</th>\n",
       "      <td>0.41525</td>\n",
       "      <td>0.10115</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.264603</td>\n",
       "      <td>0.986893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_median_ms  test_median_ms  train_mem_median_mb  \\\n",
       "model                                                                 \n",
       "QDA                    0.49545         7.29685             0.011452   \n",
       "TensorizedQDA          0.42880         2.44300             0.011360   \n",
       "FastQDA                0.40715         0.09810             0.011269   \n",
       "EfficientQDA           0.41525         0.10115             0.011177   \n",
       "\n",
       "               test_mem_median_mb  mean_accuracy  \n",
       "model                                             \n",
       "QDA                      0.003777       0.987049  \n",
       "TensorizedQDA            0.004147       0.986369  \n",
       "FastQDA                  0.264603       0.987165  \n",
       "EfficientQDA             0.264603       0.986893  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Levantamos el dataset Wine, que tiene 13 features y 178 observaciones en total\n",
    "\n",
    "X_full, y_full = get_penguins_dataset()\n",
    "\n",
    "# Encodeamos a número las clases\n",
    "\n",
    "y_full_encoded = label_encode(y_full)\n",
    "\n",
    "# Generamos el benchmark\n",
    "\n",
    "b = Benchmark(\n",
    "    X_full, y_full_encoded,\n",
    "    n_runs = 1000,\n",
    "    warmup = 20,\n",
    "    mem_runs = 200,\n",
    "    test_sz = 0.3,\n",
    "    same_splits = False\n",
    ")\n",
    "\n",
    "# Bencheamos implementaciones\n",
    "\n",
    "to_bench = [QDA, TensorizedQDA, FastQDA, EfficientQDA]\n",
    "\n",
    "for model in to_bench:\n",
    "    b.bench(model)\n",
    "\n",
    "# Hacemos un summary\n",
    "\n",
    "b.summary()\n",
    "\n",
    "# Son muchos datos! nos quedamos con un par nomás\n",
    "\n",
    "summ = b.summary()\n",
    "\n",
    "# Como es un pandas DataFrame, subseteamos columnas fácil\n",
    "\n",
    "summ[['train_median_ms', 'test_median_ms', 'train_mem_median_mb', 'test_mem_median_mb', 'mean_accuracy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cholesky\n",
    "\n",
    "Hasta ahora todos los esfuerzos fueron enfocados en realizar una predicción más rápida. Los tiempos de entrenamiento (teóricos al menos) siguen siendo los mismos o hasta (minúsculamente) peores, dado que todas las mejoras siguen llamando al método `_fit_params` original de `QDA`.\n",
    "\n",
    "La descomposición/factorización de [Cholesky](https://en.wikipedia.org/wiki/Cholesky_decomposition#Statement) permite factorizar una matriz definida positiva $A = LL^T$ donde $L$ es una matriz triangular inferior. En particular, si bien se asume que $p \\ll n$, invertir la matriz de covarianzas $\\Sigma$ para cada clase impone un cuello de botella que podría alivianarse. Teniendo en cuenta que las matrices de covarianza son simétricas y salvo degeneración, definidas positivas, Cholesky como mínimo debería permitir invertir la matriz más rápido.\n",
    "\n",
    "*Nota: observar que calcular* $A^{-1}b$ *equivale a resolver el sistema* $Ax=b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Diferencias entre implementaciones de `QDA_Chol`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Si una matriz $A$ tiene fact. de Cholesky $A=LL^T$, expresar $A^{-1}$ en términos de $L$. ¿Cómo podría esto ser útil en la forma cuadrática de QDA?\n",
    "\n",
    "   - Si $A$ es simétrica definida positiva y tiene factorización de Cholesky  \n",
    "\n",
    "     $A=LL^T, L$ triangular inferior,\n",
    "\n",
    "     entonces su inversa se puede expresar directamente en términos de $L$:  \n",
    "\n",
    "     $A^{-1} = (L L^{\\top})^{-1} = (L^{\\top})^{-1} L^{-1} = L^{-\\top} L^{-1}$\n",
    "\n",
    "   - En QDA permite resolver la forma cuadrática sin tener que invertir la matriz de covarianzas. Es mas sencillo invertir y calcular el determinante de una matriz triangular.\n",
    "     \n",
    "     $Q = (x-\\hat{\\mu}_j)^\\top \\hat{\\Sigma}_j^{-1}(x-\\hat{\\mu}_j) = (x-\\hat{\\mu}_j)^\\top \\hat{L}_j^{-T}\\hat{L}_j^{-1}(x-\\hat{\\mu}_j)$\n",
    "\n",
    "     Sea $u_j = (x-\\hat{\\mu}_j)$\n",
    "     \n",
    "     $Q = u_j^{T}\\hat{L}_j^{-T}\\hat{L}_j^{-1}u_j = (\\hat{L}_j^{-1}u_j)^{T}(\\hat{L}_j^{-1}u_j) = \\|\\hat{L}_j^{-1}u_j\\|_2^2.$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Explicar las diferencias entre `QDA_Chol1`y `QDA` y cómo `QDA_Chol1` llega, paso a paso, hasta las predicciones.\n",
    "\n",
    "   - `QDA_Chol1` al momento de entrenar calcula la inversa de las matrices triangualares $L$ en lugar de invertir las matrices de covarianzas completas.\n",
    "   \n",
    "    ```python\n",
    "      self.L_invs = [\n",
    "            LA.inv(cholesky(np.cov(X[:,y.flatten()==idx], bias=True), lower=True))\n",
    "                for idx in range(len(self.log_a_priori))\n",
    "        ]  \n",
    "    ```\n",
    "\n",
    "    - `QDA_Chol1` al momento de predecir, en el cálculo de la log-condicional de una clase, obtiene $y = \\hat{L}^{-1}(x - \\hat{\\mu})$. \n",
    "      \n",
    "      Y luego su valor como: $\\log |\\hat{L}^{-1}| - \\frac{1}{2} \\|y\\|_2^2$\n",
    "\n",
    "      El cálculo del determinante de la matriz triangular se obtiene como el producto de los elementos de su diagonal. El factor $-\\frac{1}{2}$ desaparece al estar calculando el determinante de la inversa y que el $|L|^2 = |\\Sigma|$\n",
    "\n",
    "    ```python\n",
    "      def _predict_log_conditional(self, x, class_idx):\n",
    "        L_inv = self.L_invs[class_idx]\n",
    "        unbiased_x =  x - self.means[class_idx]\n",
    "\n",
    "        y = L_inv @ unbiased_x\n",
    "\n",
    "        return np.log(L_inv.diagonal().prod()) -0.5 * (y**2).sum() \n",
    "    ```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. ¿Cuáles son las diferencias entre `QDA_Chol1`, `QDA_Chol2` y `QDA_Chol3`?\n",
    "\n",
    "   `QDA_Chol1`: Durante el entrenamiento calcula y guarda la inversa de la matriz triangular inferior de Cholesky de la matriz de covarianzas de cada clase. En la prediccion calcula $y$ para cada clase como el producto de la inversa almacenada `L_inv` y `unbiased_x`.\n",
    "\n",
    "   `QDA_Chol2`: No invierte la matriz triangular en el entrenamiento y en la predicción obtiene $y$ resolviendo el sistema linal de la matriz triangular para `L` y `unbiased_x`.\n",
    "\n",
    "   `QDA_Chol3`: Identico a `QDA_Chol1` con la sola diferencia de que utiliza la función $dtrtri$ para calcular especificamente la inversa de una matriz triangular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Comparar la performance de las 7 variantes de QDA implementadas hasta ahora ¿Qué se observa?¿Hay alguna de las implementaciones de `QDA_Chol` que sea claramente mejor que las demás?¿Alguna que sea peor?\n",
    "\n",
    "Tanto `Chol1`como `Chol3`bajan el tiempo de prueba respecto a `QDA`. `Chol2` tiene peor desenpeño que los otros dos, probablemente porque la cantidad de caracteristicas del dataset es baja y resulta menos costoso invertir la matriz triangular en el entrenamiento y realizar una multiplicacion en la predicción que resolver la matriz triangular en la predicción de `Chol2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc50c4c8a67a444e892f47d75621055d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol1 (MEM):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543eedc1386d415a9e4043bfb222027e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol1 (TIME):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4665e6b565624ca3a3860f0e7dcb2831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol2 (MEM):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fab50eb4c1c476092735fe152271ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol2 (TIME):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32aea1a37d5b4c2d810fe19c42ddc96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol3 (MEM):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d6b37fc8e743fbb537b1aa7ba9fa3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol3 (TIME):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_median_ms</th>\n",
       "      <th>test_median_ms</th>\n",
       "      <th>train_mem_median_mb</th>\n",
       "      <th>test_mem_median_mb</th>\n",
       "      <th>mean_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.49545</td>\n",
       "      <td>7.29685</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.987049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorizedQDA</th>\n",
       "      <td>0.42880</td>\n",
       "      <td>2.44300</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.986369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FastQDA</th>\n",
       "      <td>0.40715</td>\n",
       "      <td>0.09810</td>\n",
       "      <td>0.011269</td>\n",
       "      <td>0.264603</td>\n",
       "      <td>0.987165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EfficientQDA</th>\n",
       "      <td>0.41525</td>\n",
       "      <td>0.10115</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.264603</td>\n",
       "      <td>0.986893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol1</th>\n",
       "      <td>0.70525</td>\n",
       "      <td>5.50220</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.986612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol2</th>\n",
       "      <td>0.50340</td>\n",
       "      <td>10.19520</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.986903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol3</th>\n",
       "      <td>0.52190</td>\n",
       "      <td>4.77885</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.987078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_median_ms  test_median_ms  train_mem_median_mb  \\\n",
       "model                                                                 \n",
       "QDA                    0.49545         7.29685             0.011452   \n",
       "TensorizedQDA          0.42880         2.44300             0.011360   \n",
       "FastQDA                0.40715         0.09810             0.011269   \n",
       "EfficientQDA           0.41525         0.10115             0.011177   \n",
       "QDA_Chol1              0.70525         5.50220             0.011360   \n",
       "QDA_Chol2              0.50340        10.19520             0.011543   \n",
       "QDA_Chol3              0.52190         4.77885             0.011452   \n",
       "\n",
       "               test_mem_median_mb  mean_accuracy  \n",
       "model                                             \n",
       "QDA                      0.003777       0.987049  \n",
       "TensorizedQDA            0.004147       0.986369  \n",
       "FastQDA                  0.264603       0.987165  \n",
       "EfficientQDA             0.264603       0.986893  \n",
       "QDA_Chol1                0.003727       0.986612  \n",
       "QDA_Chol2                0.004162       0.986903  \n",
       "QDA_Chol3                0.003674       0.987078  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como es una clase, podemos seguir bencheando más después\n",
    "\n",
    "b.bench(QDA_Chol1)\n",
    "b.bench(QDA_Chol2)\n",
    "b.bench(QDA_Chol3)\n",
    "\n",
    "# Hacemos un summary\n",
    "\n",
    "summ = b.summary()\n",
    "\n",
    "# Como es un pandas DataFrame, subseteamos columnas fácil\n",
    "\n",
    "summ[['train_median_ms', 'test_median_ms', 'train_mem_median_mb', 'test_mem_median_mb', 'mean_accuracy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Implementar el modelo `TensorizedChol` paralelizando sobre clases/observaciones según corresponda. Se recomienda heredarlo de alguna de las implementaciones de `QDA_Chol`, aunque la elección de cuál de ellas queda a cargo del alumno según lo observado en los benchmarks de puntos anteriores.\n",
    "\n",
    "    Implementado en base/cholesky.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Implementar el modelo `EfficientChol` combinando los insights de `EfficientQDA` y `TensorizedChol`. Si se desea, se puede implementar `FasterChol` como ayuda, pero no se contempla para el punto.\n",
    "\n",
    "    Implementado en base/cholesky.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EF80Pck2RmaC"
   },
   "source": [
    "13. Comparar la performance de las 9 variantes de QDA implementadas ¿Qué se observa? A modo de opinión ¿Se condice con lo esperado?\n",
    "\n",
    "    Todas las implementaciones tienen precisión similar. En entrenamiento todas tienen tiempos y uso de memoria similares. \n",
    "\n",
    "    `TensorizedQDA` y `TensorizedChol` logran la mejorar el tiempo en test respecto `QDA` y las versiones `QDA_Chol` por vectorización.\n",
    "\n",
    "    Las implementaciones `Fast/Efficient` mejoran aun mas la velocidad, a costo de aumentar el uso de memoria.\n",
    "\n",
    "    `EfficientChol` pareciera ser la de mejor velocidad con un incremento de memoria menor a `Fast/EfficientQDA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6de6336fc374b08b9935ec8ae80aeeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TensorizedChol (MEM):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c24035c86a4e54851084bacef587c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TensorizedChol (TIME):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390dd8b94aca4808958beb5393fae872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EfficientChol (MEM):   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21910d1f86a47e99eac7433262b490d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EfficientChol (TIME):   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_median_ms</th>\n",
       "      <th>test_median_ms</th>\n",
       "      <th>train_mem_median_mb</th>\n",
       "      <th>test_mem_median_mb</th>\n",
       "      <th>mean_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.49545</td>\n",
       "      <td>7.29685</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.987049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorizedQDA</th>\n",
       "      <td>0.42880</td>\n",
       "      <td>2.44300</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.986369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FastQDA</th>\n",
       "      <td>0.40715</td>\n",
       "      <td>0.09810</td>\n",
       "      <td>0.011269</td>\n",
       "      <td>0.264603</td>\n",
       "      <td>0.987165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EfficientQDA</th>\n",
       "      <td>0.41525</td>\n",
       "      <td>0.10115</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>0.264603</td>\n",
       "      <td>0.986893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol1</th>\n",
       "      <td>0.70525</td>\n",
       "      <td>5.50220</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.986612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol2</th>\n",
       "      <td>0.50340</td>\n",
       "      <td>10.19520</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.986903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol3</th>\n",
       "      <td>0.52190</td>\n",
       "      <td>4.77885</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.987078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorizedChol</th>\n",
       "      <td>0.55125</td>\n",
       "      <td>3.54695</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.986825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EfficientChol</th>\n",
       "      <td>0.38600</td>\n",
       "      <td>0.04950</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>0.042450</td>\n",
       "      <td>0.987000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                train_median_ms  test_median_ms  train_mem_median_mb  \\\n",
       "model                                                                  \n",
       "QDA                     0.49545         7.29685             0.011452   \n",
       "TensorizedQDA           0.42880         2.44300             0.011360   \n",
       "FastQDA                 0.40715         0.09810             0.011269   \n",
       "EfficientQDA            0.41525         0.10115             0.011177   \n",
       "QDA_Chol1               0.70525         5.50220             0.011360   \n",
       "QDA_Chol2               0.50340        10.19520             0.011543   \n",
       "QDA_Chol3               0.52190         4.77885             0.011452   \n",
       "TensorizedChol          0.55125         3.54695             0.011374   \n",
       "EfficientChol           0.38600         0.04950             0.011360   \n",
       "\n",
       "                test_mem_median_mb  mean_accuracy  \n",
       "model                                              \n",
       "QDA                       0.003777       0.987049  \n",
       "TensorizedQDA             0.004147       0.986369  \n",
       "FastQDA                   0.264603       0.987165  \n",
       "EfficientQDA              0.264603       0.986893  \n",
       "QDA_Chol1                 0.003727       0.986612  \n",
       "QDA_Chol2                 0.004162       0.986903  \n",
       "QDA_Chol3                 0.003674       0.987078  \n",
       "TensorizedChol            0.003361       0.986825  \n",
       "EfficientChol             0.042450       0.987000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como es una clase, podemos seguir bencheando más después\n",
    "\n",
    "b.bench(TensorizedChol)\n",
    "b.bench(EfficientChol)\n",
    "\n",
    "# Hacemos un summary\n",
    "\n",
    "summ = b.summary()\n",
    "\n",
    "# Como es un pandas DataFrame, subseteamos columnas fácil\n",
    "\n",
    "summ[['train_median_ms', 'test_median_ms', 'train_mem_median_mb', 'test_mem_median_mb', 'mean_accuracy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcqVvRSLwaEZ"
   },
   "source": [
    "## Importante:\n",
    "\n",
    "Las métricas que se observan al realizar benchmarking son muy dependientes del código que se ejecuta, y por tanto de las versiones de las librerías utilizadas. Una forma de unificar esto es utilizando un gestor de versiones y paquetes como _uv_ o _Poetry_, otra es simplemente usando una misma VM como la que provee Colab.\n",
    "\n",
    "**Cada equipo debe informar las versiones de Python, NumPy y SciPy con que fueron obtenidos los resultados. En caso de que sean múltiples, agregar todos los casos**. La siguiente celda provee una ayuda para hacerlo desde un notebook, aunque como es una secuencia de comandos también sirve para consola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.7 | packaged by conda-forge | (main, Oct  4 2024, 15:47:54) [MSC v.1941 64 bit (AMD64)]\n",
      "numpy: 1.26.4\n",
      "scipy: 1.15.2\n"
     ]
    }
   ],
   "source": [
    "# Version que deberia funcionar en todos los entornos\n",
    "\n",
    "import sys\n",
    "print(\"Python:\", sys.version)\n",
    "\n",
    "# importlib.metadata es estándar desde Python 3.8; en Colab también está.\n",
    "try:\n",
    "    from importlib.metadata import version, PackageNotFoundError\n",
    "except Exception:\n",
    "    from importlib_metadata import version, PackageNotFoundError  # backport, por si acaso\n",
    "\n",
    "for pkg in [\"numpy\", \"scipy\"]:\n",
    "    try:\n",
    "        print(f\"{pkg}:\", version(pkg))\n",
    "    except PackageNotFoundError:\n",
    "        print(f\"{pkg}: NO INSTALADO\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
